<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <title>Spidey-Sense Field Test</title>
  <style>
    html, body { margin: 0; padding: 0; background: #000; color: #fff; font-family: system-ui, -apple-system; }
    #ui { position: fixed; top: 0; left: 0; right: 0; padding: 8px 12px; background: rgba(0,0,0,.45); backdrop-filter: blur(4px); display: flex; gap: 8px; align-items: center; z-index: 10; }
    #status { font-size: 14px; opacity: .9; }
    #speakBtn, #startBtn { padding: 8px 12px; border-radius: 10px; border: 0; background: #e50914; color: #fff; font-weight: 600; }
    #startBtn { background: #1e90ff; }
    #advice { position: fixed; bottom: 0; left: 0; right: 0; text-align: center; padding: 10px 12px; font-size: 18px; background: rgba(0,0,0,.5); }
    #wrap { position: relative; width: 100vw; height: 100vh; overflow: hidden; }
    video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; }
    .badge { font-size: 12px; opacity: .85; margin-left: auto; }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>
</head>
<body>
  <div id="ui">
    <button id="startBtn">Activate Spidey-Sense</button>
    <button id="speakBtn">Test Voice</button>
    <span id="status">Idle</span>
    <span class="badge">Left / Center / Right + Nearness</span>
  </div>
  <div id="wrap">
    <video id="video" playsinline muted></video>
    <canvas id="canvas"></canvas>
  </div>
  <div id="advice">Ready.</div>

  <script>
  // ====== CONFIG ======
  const BACKEND_BASE = ""; // same origin. If your backend runs elsewhere, e.g. "http://192.168.1.50:5000"
  const USE_ELEVENLABS = true; // try server TTS first; will fall back if it fails
  const MIN_SCORE = 0.5;       // detector confidence
  const DETECT_EVERY_MS = 200; // run inference ~5Hz
  const SPEAK_EVERY_MS  = 1800; // rate-limit spoken guidance
  const TARGET_CLASSES = new Set([
    "person","bicycle","car","motorcycle","bus","truck","bench","chair","sofa","potted plant","tv","sink","refrigerator","backpack","umbrella","handbag","tie","suitcase"
  ]);

  // ====== ELEMENTS ======
  const video  = document.getElementById("video");
  const canvas = document.getElementById("canvas");
  const ctx    = canvas.getContext("2d");
  const statusEl = document.getElementById("status");
  const adviceEl = document.getElementById("advice");
  const startBtn = document.getElementById("startBtn");
  const speakBtn = document.getElementById("speakBtn");

  let model = null;
  let lastSpokenAt = 0;
  let running = false;

  function setStatus(s){ statusEl.textContent = s; }
  function setAdvice(s){ adviceEl.textContent = s; }

  // Camera setup
  async function initCamera() {
    const stream = await navigator.mediaDevices.getUserMedia({
      audio: false,
      video: { facingMode: "environment" }
    });
    video.srcObject = stream;
    await video.play();

    // size canvas to video
    const resize = () => {
      const w = video.videoWidth || window.innerWidth;
      const h = video.videoHeight || window.innerHeight;
      canvas.width = w;
      canvas.height = h;
    };
    resize();
    window.addEventListener("resize", resize);
  }

  // Simple distance heuristic: bigger box area => nearer
  function nearness(label, box, w, h) {
    const area = (box.width * box.height) / (w * h + 1e-6);
    if (area > 0.12) return "near";     // very close
    if (area > 0.05) return "mid";      // medium
    return "far";
  }

  // Sector split by bbox center x
  function sectorFor(box, w) {
    const cx = box.x + box.width/2;
    const u = cx / w;
    if (u < 0.33) return "left";
    if (u > 0.66) return "right";
    return "center";
  }

  function decideGuidance(objects) {
    // Penalize sectors with near/mid obstacles; reward free sectors
    const score = {left: 1.0, center: 1.0, right: 1.0};
    for (const o of objects) {
      const s = o.sector;
      if (o.nearness === "near") score[s] -= 0.9;
      else if (o.nearness === "mid") score[s] -= 0.5;
      else score[s] -= 0.2;
    }
    // pick best sector
    const entries = Object.entries(score).sort((a,b)=>b[1]-a[1]);
    const [best, bestVal] = entries[0];

    if (bestVal < 0.3) {
      return {text: "Stop. Re-route.", action: "stop"};
    }
    if (best === "left")  return {text: "Veer left.", action: "left"};
    if (best === "right") return {text: "Veer right.", action: "right"};
    return {text: "Straight ahead.", action: "forward"};
  }

  async function speak(text) {
    // Try ElevenLabs via your backend
    if (USE_ELEVENLABS) {
      try {
        const r = await fetch((BACKEND_BASE || "") + "/api/speak", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text })
        });
        if (r.ok) {
          const blob = await r.blob();
          const url  = URL.createObjectURL(blob);
          const audio = new Audio(url);
          await audio.play();
          return;
        }
      } catch (e) {
        // fall through to Web Speech
      }
    }
    // Fallback: Web Speech API (works offline, no keys)
    try {
      const u = new SpeechSynthesisUtterance(text);
      u.rate = 1.05;
      u.pitch = 1.0;
      speechSynthesis.cancel();
      speechSynthesis.speak(u);
    } catch(e) {
      console.warn("Speech fallback failed:", e);
    }
  }

  function draw(objects) {
    const w = canvas.width, h = canvas.height;
    ctx.clearRect(0,0,w,h);
    ctx.lineWidth = 3;
    ctx.font = "16px system-ui";
    ctx.textBaseline = "top";

    for (const o of objects) {
      // color by sector
      const color = o.sector === "left" ? "#1e90ff" : o.sector === "center" ? "#ffd000" : "#e50914";
      ctx.strokeStyle = color;
      ctx.fillStyle = color;
      ctx.globalAlpha = 0.9;

      ctx.strokeRect(o.bbox.x, o.bbox.y, o.bbox.width, o.bbox.height);
      const label = `${o.class} ${Math.round(o.score*100)}% • ${o.sector} • ${o.nearness}`;
      const tw = ctx.measureText(label).width + 8;
      const th = 20;
      ctx.fillRect(o.bbox.x, Math.max(0, o.bbox.y-22), tw, th);
      ctx.fillStyle = "#000";
      ctx.fillText(label, o.bbox.x+4, Math.max(0, o.bbox.y-20));
    }
  }

  async function mainLoop() {
    if (!running) return;
    try {
      const preds = await model.detect(video);
      const w = canvas.width, h = canvas.height;
      const objects = [];
      for (const p of preds) {
        if (p.score < MIN_SCORE) continue;
        if (!TARGET_CLASSES.has(p.class)) continue;
        const [x,y,wBox,hBox] = p.bbox;
        const o = {
          class: p.class, score: p.score,
          bbox: { x, y, width: wBox, height: hBox },
        };
        o.nearness = nearness(o.class, o.bbox, w, h);
        o.sector   = sectorFor(o.bbox, w);
        objects.push(o);
      }
      draw(objects);

      const guide = decideGuidance(objects);
      setAdvice(guide.text);

      const now = performance.now();
      if (now - lastSpokenAt > SPEAK_EVERY_MS) {
        lastSpokenAt = now;
        speak(guide.text);
      }
      setStatus(`${objects.length} objects`);
    } catch (e) {
      setStatus("Error: " + e.message);
    } finally {
      setTimeout(mainLoop, DETECT_EVERY_MS);
    }
  }

  // Buttons
  startBtn.addEventListener("click", async () => {
    try {
      startBtn.disabled = true;
      setStatus("Loading model…");
      await initCamera();
      setStatus("Downloading detector…");
      model = await cocoSsd.load({ base: "lite_mobilenet_v2" }); // faster, phone-friendly
      setStatus("Running");
      running = true;
      mainLoop();
    } catch (e) {
      setStatus("Init error: " + e.message);
      startBtn.disabled = false;
    }
  });

  speakBtn.addEventListener("click", () => speak("Spidey-Sense voice check."));
  </script>
</body>
</html>
